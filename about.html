---
layout: null
section-type: about
title: About
---
## Recent News
<p style="text-align: justify">
    <strong>2024.07.18</strong> - The 2nd World AI4S Prize has been officially launched. Please check the <a href="http://competition.sais.com.cn/competitionDetail/532230/format">competition website</a> for the Life Science Track I co-orgnized.
    <br><strong>2024.07.16</strong> - Our paper "Parameter-Efficient Complementary Expert Learning for Long-Tailed Visual Recognition" has been accepted by ACM Multimedia 2024. 
    <br><strong>2024.07.10</strong> - SkySense has been <a href="https://www.csgpc.org/index.php/detail/23612.html">open-sourced on condition</a> and made available to certain institutions for research purpose. For those who are interested please contact <a href="mailto:yansheng.li@whu.edu.cn">Prof. Yansheng Li</a>.
</p>

## ABOUT ME
<p style="text-align: justify">
    I currently hold the position of Senior Research Fellow at the Shanghai Academy of Artificial Intelligence for Science (SAIS). My work at SAIS focuses on leveraging Artificial Intelligence to advance Life Science, particularly in the area of Multiomics & Multimodal Foundation Models and their clinical applications. This role builds upon my extensive experience at Ant & Alibaba Group, where I specialized in Computer Vision and Vision Foundation Model.
</p>

<p style="text-align: justify">
    Previously, I served as a Senior Research Engineer at Ant & Alibaba Group. Over the course of my 8+ years there, I applied my expertise in digital signal processing, computer vision, and multimodal perception to develop innovative and award-winning AI products, such as <a href="https://emerj.com/ai-sector-overviews/ai-auto-insurance-current-applications/">定损宝</a> (recipient of the <a href="https://www.hcwgx.com/1974.html">Shenzhen 2018 Fintech Award</a>) and <a href="https://mp.weixin.qq.com/s/u7g_T5T2SDDcJO3FNIYBsQ">亿亩田</a> (recipient of the <a href="https://www.ccf.org.cn/Focus/2022-11-08/776112.shtml">CCF 2022 Technology Advancing Award</a>). Additionally, I was an executive member of the <a href="http://news.whu.edu.cn/info/1002/69161.htm">Wuhan University - Ant Group United Laboratory</a>, where I collaborated with leading researchers and engineers to develop <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Guo_SkySense_A_Multi-Modal_Remote_Sensing_Foundation_Model_Towards_Universal_Interpretation_CVPR_2024_paper.pdf">SkySense</a>, a cutting-edge vision foundation model for remote sensing imagery.
</p>

<p style="text-align: justify">
I hold a Master's degree in Communication Systems from the Swiss Federal Institute of Technology in Lausanne (EPFL) and a Bachelor's degree with honors from Zhejiang University, majoring in Information and Communication Engineering. My professional journey in both large corporation and innovative start-up across Europe (<em>i.e.</em> <a href="https://www.sony.com/en/SonyInfo/research/about/stuttgart-laboratory1/">Sony</a> and <a href="https://tractable.ai/">Tractable Ltd</a>) has afforded me valuable experience.
</p>

<p style="text-align: justify">
My current research interests encompass Multiomics Foundation Model, Computer Vision, and Multimodal Perception. I have published 10 papers and served as a reviewer for 5+ prestigious conferences and journals. I hold 10+ international patents, issued by patent offices in Europe, the United States, Japan, Korea, Singapore, and other countries worldwide. I am deeply passionate about solving challenging problems and creating impactful solutions that might benefit the whole world.
</p>

<hr>

<h3 style="text-align: left">
    Publications
</h3>

<h4 style="text-align: left">
    亿亩田 with Ant & MYBank & Wuhan University
</h4>
<p style="text-align: justify">- Semi-supervised segmentation for time series images. <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Lao_Simultaneously_Short-_and_Long-Term_Temporal_Modeling_for_Semi-Supervised_Video_Semantic_CVPR_2023_paper.html">Simultaneously Short- and Long-Term Temporal Modeling for Semi-Supervised Video Semantic Segmentation</a>
    <br><small>Jiangwei Lao, Weixiang Hong, <em><ins><strong>Xin Guo</strong></ins></em>, Yingying Zhang, Jian Wang, Jingdong Chen, Wei Chu</small>
    <br><strong>CVPR 2023</strong>
</p>

<p style="text-align: justify">- Biomass estimation for ESG. <a href="https://ieeexplore.ieee.org/document/10282061">Wall-to-Wall Above-Ground Biomass Estimation with Alos-2 Palsar-2 L-Band SAR Data and GEDI</a>
    <br><small>Yu Zhao, <em><ins><strong>Xin Guo</strong></ins></em>, Liheng Zhong, Jian Wang, Jingdong Chen</small>
    <br><strong>IGARSS 2023</strong>
</p>

<p style="text-align: justify">- Knowledge distillation for efficient model deployment. <a href="https://papers.neurips.cc/paper_files/paper/2023/file/34260a400e39a802961470b3d3de99cc-Paper-Conference.pdf">Towards Efficient Pre-Trained Language Model via Feature Correlation Distillation</a>
    <br><small>Kun Huang, <em><ins><strong>Xin Guo</strong></ins></em>, Meng Wang</small>
    <br><strong>NeurIPS 2023</strong>
</p>

<p style="text-align: justify">- Vision foundation model for remote sensing. <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Guo_SkySense_A_Multi-Modal_Remote_Sensing_Foundation_Model_Towards_Universal_Interpretation_CVPR_2024_paper.pdf">SkySense: A Multi-Modal Remote Sensing Foundation Model Towards Universal Interpretation for Earth Observation Imagery</a>
    <br><small><em><ins><strong>Xin Guo*</strong></ins></em>, Jiangwei Lao*, Bo Dang*, Yingying Zhang, Lei Yu, Lixiang Ru, Liheng Zhong, Ziyuan Huang, Kang Wu, Dingxiang Hu, Huimei He, Jian Wang, Jingdong Chen, Ming Yang, Yongjun Zhang, Yansheng Li</small>
    <br><strong>CVPR 2024</strong>
</p>

<p style="text-align: justify">- Efficient pre-training for vision foundation models. <a href="">POA: Pre-training Once for Models of All Sizes</a>
    <br><small>Yingying Zhang, <em><ins><strong>Xin Guo</strong></ins></em>, Jiangwei Lao, Lei Yu, Lixiang Ru, Jian Wang, Guo Ye, Huimei He, Jingdong Chen, Ming Yang</small>
    <br><strong>ECCV 2024</strong>
</p>

<p style="text-align: justify">- Improved long-tailed visual classification. <a href="">Parameter-Efficient Complementary Expert Learning for Long-Tailed Visual Recognition</a>
    <br><small>Lixiang Ru, <em><ins><strong>Xin Guo</strong></ins></em>, Lei Yu, Yingying Zhang, Jiangwei Lao, Jian Wang, Jingdong Chen, Yansheng Li, Ming Yang</small>
    <br><strong>ACM Multimedia 2024</strong>
</p>

<h4 style="text-align: left">
    定损宝 with Ant
</h4>
<p style="text-align: justify">- <a href="https://ojs.aaai.org/index.php/AAAI/article/view/7110">Automatic Car Damage Assessment System: Reading and Understanding Videos as Professional Insurance Inspectors</a>
    <br><small>Wei Zhang, Yuan Cheng, <em><ins><strong>Xin Guo</strong></ins></em>, Qingpei Guo, Jian Wang, Qing Wang, Chen Jiang, Meng Wang, Furong Xu, Wei Chu</small>
    <br><strong>AAAI 2020</strong>
</p>

<h4 style="text-align: left">
    Blind source seperation with Sony
</h4> 
<p style="text-align: justify">- <a href="https://ieeexplore.ieee.org/document/7177972">NMF-based blind source separation using a linear predictive coding error clustering criterion</a>
    <br><small><em><ins><strong>Xin Guo</strong></ins></em>, Stefan Uhlich, Yuki Mitsufuji</small>
    <br><strong>ICASSP 2015</strong>
</p>

<h4 style="text-align: left">
    Other collaborations
</h4>
<p style="text-align: justify">- <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Uncertainty-guided_Learning_for_Improving_Image_Manipulation_Detection_ICCV_2023_paper.pdf">Uncertainty-guided Learning for Improving Image Manipulation Detection</a>
    <br><small>Kaixiang Ji, Feng Chen, <em><ins><strong>Xin Guo</strong></ins></em>, Yadong Xu, Jian Wang, Jingdong Chen</small>
    <br><strong>ICCV 2023</strong>
</p>

<p style="text-align: justify">- <a href="">Fine-Grained Scene Graph Generation via Sample-Level Bias Prediction</a>
    <br><small>Yansheng Li, Tingzhu Wang, Kang Wu, Linlin Wang, <em><ins><strong>Xin Guo</strong></ins></em>, Wenbin Wang</small>
    <br><strong>ECCV 2024</strong>
</p>

<p style="text-align: justify">- <a href="https://arxiv.org/pdf/2401.06550">Multimodal Urban Areas of Interest Generation via Remote Sensing Imagery and Geographical Prior</a>
    <br><small>Chuanji Shi, Yingying Zhang, Jiaotuan Wang, <em><ins><strong>Xin Guo</strong></ins></em>, Qiqi Zhu</small>
    <br><small>arXiv preprint</small>
</p>

<p style="text-align: justify">- <a href="https://arxiv.org/pdf/2405.03318">Enhancing DETRs Variants through Improved Content Query and Similar Query Aggregation</a>
    <br><small>Yingying Zhang, Chuanji Shi, <em><ins><strong>Xin Guo</strong></ins></em>, Jiangwei Lao, Jian Wang, Jiaotuan Wang, Jingdong Chen</small>
    <br><small>arXiv preprint</small>
</p>

<hr>

<h3 style="text-align: left">
    SELECTED Patents   
</h3>

<p style="text-align: justify">1. <strong>EP3201917B1</strong>: <em><ins><strong>Xin Guo</strong></ins></em>, Stefan Uhlich, Yuhki Mitsufuji, <a href="https://patents.google.com/patent/EP3201917B1/en">Method, apparatus and system for blind source separation</a></p>

<p style="text-align: justify">2. <strong>US10943126B2</strong>: <em><ins><strong>Xin Guo</strong></ins></em>, Yuan Cheng, Chen Jiang, <a href="https://patents.google.com/patent/US10943126B2/en">Method and apparatus for processing video stream</a></p>

<p style="text-align: justify">3. <strong>US11216690B2</strong>: <em><ins><strong>Xin Guo</strong></ins></em>, Yuan Cheng, Jun Huang, <a href="https://patents.google.com/patent/US11216690B2/en">System and method for performing image processing based on a damage assessment image judgement model</a></p>

<p style="text-align: justify">4. <strong>SG11202011405YA</strong>: <em><ins><strong>Xin Guo</strong></ins></em>, Yuan Cheng, Chen Jiang, Zhihong Lu, <a href="https://patents.google.com/patent/SG11202011405YA/en">Image processing method and apparatus</a></p>

<p style="text-align: justify">5. <strong>US11049334B2</strong>: Haitao Zhang, Juan Xu, Jinlong Hou, Jian Wang, <em><ins><strong>Xin Guo</strong></ins></em>, Danni Cheng, Yue Hu, Bokun Wu, Yanqing Chen, <a href="https://patents.google.com/patent/US11049334B2/en">Picture-based vehicle loss assessment</a></p>

<p style="text-align: justify">6. <strong>US010846556B2</strong>: Jinlong Hou, Haitao Zhang, <em><ins><strong>Xin Guo</strong></ins></em>, Juan Xu, Jian Wang, Yuan Cheng, Danni Cheng, <a href="https://patents.google.com/patent/US10846556B2/en">Vehicle insurance image processing method, apparatus, server, and system</a></p>

<p style="text-align: justify">7. <strong>US11151384B2</strong>: Haitao Zhang, Jinlong Hou, <em><ins><strong>Xin Guo</strong></ins></em>, Yuan Cheng, Jian Wang, Juan Xu, Fan Zhou, Kan Zhang, <a href="https://patents.google.com/patent/US11151384B2/en">Method and apparatus for obtaining vehicle loss assessment image, server and terminal device</a></p>

<p style="text-align: justify">8. <strong>US10817956B2</strong>: Haitao Zhang, Juan Xu, Jinlong Hou, Jian Wang, <em><ins><strong>Xin Guo</strong></ins></em>, Danni Cheng, Yue Hu, Bokun Wu, Yanqing Chen, <a href="https://patents.google.com/patent/US10817956B2/en">Image-based vehicle damage determining method and apparatus, and electronic device</a></p>

<p style="text-align: justify">9. <strong>KR102418446B1</strong>: Haitao Zhang, Juan Xu, Jinlong Hou, Jian Wang, <em><ins><strong>Xin Guo</strong></ins></em>, Danni Cheng, Yue Hu, Bokun Wu, Yanqing Chen, <a href="https://patents.google.com/patent/KR102418446B1/en">Picture-based vehicle damage assessment method and apparatus, and electronic device</a></p>

<p style="text-align: justify">10. <strong>JP6905081B2</strong>: Haitao Zhang, Jinlong Hou, <em><ins><strong>Xin Guo</strong></ins></em>, Yuan Cheng, Jian Wang, Juan Xu, Fan Zhou, Kan Zhang, <a href="https://patents.google.com/patent/JP6905081B2/en">Methods and Devices for Obtaining Vehicle Loss Assessment Images and Devices, Servers, and Terminal Devices</a></p>

<hr>

<h3 style="text-align: left">
    Academic Activities
</h3>

<h4 style="text-align: left">
    Academic Services
</h4>
<p style="text-align: justify">1. Teaching Assistant: <a href="https://lcnwww.epfl.ch/gerstner/coursClassif.html">Pattern Classification and Machining Learning (2013)</a>
    <br><strong>Swiss Federal Institute of Technology in Lausanne (EPFL)</strong>, Prof. Matthias Seeger
    <br>2. Reviewer Service: <a href="https://cvpr.thecvf.com/Conferences/2024">CVPR</a>, <a href="https://neurips.cc/">NeurIPS</a>, <a href="https://kdd2024.kdd.org/">KDD</a>, <a href="https://2024.acmmm.org/">ACM Multimedia</a>, <a href="https://2024.ieeeicme.org/">ICME</a>, <a href="https://icpr2024.org/">ICPR</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36">TGRS</a>
</p>

<p style="text-align: justify"></p>

<h4 style="text-align: left">
    Interviews
</h4>
<p style="text-align: justify">
    1. <a href="https://www.rts.ch/play/tv/emission-nationale/video/dataland-emission-nationale-episode-22-saison-2017?id=10013987&station=a9e7621504c6959e35c3ecbe7f6bed0446cdf8da">Dingsunbao: An Automatic Car Damage Assessment System</a>
    <br><strong>Radio Television Suisse</strong> in <em>2018</em>, from <em>2:21:09</em> to <em>2:22:12</em>
    <br>2. <a href="https://www.businesswire.com/news/home/20181205005289/en/Alipay-Supports-Growth-Opportunities-and-Digital-Innovation-for-Start-Ups-in-Malaysia">Dingsunbao: AI-based Car Damage Assessment System</a>
    <br><strong>Alipay-NUS Enterprise Social Innovation Challenge(ANSIC)</strong> in <em>2018, Malaysia</em>
</p>

<h4 style="text-align: left">
    Competitions
</h4>
<p style="text-align: justify">
    1. <a href="https://www.aicrowd.com/challenges/esci-challenge-for-improving-product-search">KDD CUP 2022 - Amazon ESCI Challenge</a>
    <br>Ranked 16th@Task1 and 13th@Task2, among 1699 participants
    <br>2. <a href="https://www.atecup.cn/atecHome">ATEC 2022 - Remote Sensing Track</a>
    <br>Co-organizer of the competition and the corresponding <a href="https://www.bilibili.com/video/BV1jz4y1M7Sz/">Bilibili show</a>
    <br>3. <a href="https://mp.weixin.qq.com/s/t1-gMEWHaHQJdUoEDT-8gg">2024 ISPRS TC I Contest on Intelligent Interpretation for Multi-modal Remote Sensing Application</a>
    <br>Ranked 6th@Task2 and 5th@Task3, among 302 participants
    <br>4. <a href="http://competition.sais.com.cn/competitionDetail/532230/format">2024 The 2nd World AI4S Prize - Life Science Track</a>
    <br>Co-organizer of the competition
</p>

<hr>

<h3 style="text-align: left">
    Honors & Awards
</h3>

<p style="text-align: justify">2008: TOSHIBA Scholarship (Donated by Toshiba, awards 25 undergraduates each year in China)</p>

<p style="text-align: justify">2008-2012: Scholarship for Outstanding Students by Zhejiang University</p>

<p style="text-align: justify">2010: Scholarship for National Talents Program</p>

<p style="text-align: justify">2012: Outstanding Graduates by Zhejiang University (Graduated with honors)</p>

<p style="text-align: justify">2015: IEEE Signal Processing Society Travel Grant</p>

<p style="text-align: justify">2020: Alibaba Chengdian Annual Philanthropy Award</p>

<p style="text-align: justify">2023: <a href="https://mp.weixin.qq.com/s/fN0ZDv6UhhfV5mfgTKykVQ">Ant Group T-Star Award (Top 10 Innovations among Ant Group's all tech projects from 2022)</a></p>

**Please contact me for CV.**
